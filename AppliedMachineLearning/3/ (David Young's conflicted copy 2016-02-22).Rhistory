install.packages("RANN");
install.packages("RANN");
install.packages("RANN");
install.packages("stats")
install.packages("stats")
install.packages("stats")
install.packages("stats")
install.packages("stats")
install.packages("stats")
install.packages("stats")
face1.nn = 2
face1.nm = 3
face2.nn = 1
clear
?svmlight
#clear the workspace and console
rm(list=ls())
cat("\014") #code to send ctrl+L to the console and therefore clear the screen
#setup working directory
setwd('~/../Dropbox/School/Spring 2016/Machine Learning/Homeworks/1')
#read all the data into a single table
allData <- read.csv('data.txt', header = FALSE)
#import libraries to help with data splitting/partitioning,
#cross validation etc.
library(klaR)
library(caret)
#grab the features from the main data file, removing the labels
#assume no data is missing... ie: ignore missing values without noting them as NA
features <- allData[,-c(9)]
#grab the labels from the main data file... use as.factor to make
#the format comptabile with future functions to be used
labels <- as.factor(allData[,9])
#split the data into 80% training data and 20% testing data
trainingData <- createDataPartition(y=labels, p=.8, list=FALSE)
trainingFeatures <- features[trainingData,]
trainingLabels <- labels[trainingData]
testingFeatures <- features[-trainingData,]
testingLabels <- labels[-trainingData]
#train an svm using the training data
svm<-svmlight(trainingFeatures, trainingLabels)
#use the trained svm model to predict classes for the testing features
predictedLabels <- predict(svm, testingFeatures)
#determine where the classifications were correct
correctClassifications <- predictedLabels$class
#calculate the accuracy of the classifier
sum(correctClassifications==testingLabels)/(sum(correctClassifications==testingLabels)+sum(!(correctClassifications==testingLabels)))
#run an SVM
svm <- svmlight(trainingFeatures,trainingLabels) #,pathsvm='/Users/Cybelle/Documents/grad_school/school/classes/2015-2016_spring/cs498daf/svm_light')
predictedLabels<-predict(svm, testFeatures)
foo<-predictedLabels$class #"foo" = class labels (1 or 0) for each item in test set
#get classification accuracy:
accuracy<-sum(foo==testLabels)/(sum(foo==testLabels)+sum(!(foo==testLabels)))
#------------------------------------- SETUP WORK --------------------------------------
#clear the workspace and console
rm(list=ls())
cat("\014") #code to send ctrl+L to the console and therefore clear the screen
#import libraries
library(klaR)
library(caret)
library(stringr)
library(randomForest)
#----------------------------------------retrieve data ----------------------------------------
#setwd("~/Dropbox/3")
setwd('~/../Dropbox/School/Spring 2016/Machine Learning/Homeworks/3')
#retrieve all the data (each row is 147 items long: 1 label followed by 2x73 feature vectors)
data <- read.table('pubfig_dev_50000_pairs_no_header.txt',sep='\t',header=F);
#grab the labels
labels <- data[,1];
#grab the features (2x 73 features vectors)
features <- matrix(NA,nrow=nrow(data),ncol=(ncol(data)-1)/2);
#features <- data[,-1]; #accuracy: .53
#pre-process the features to yield a single 73 item feature vector that is the scaled euclidian distance between each respective feature
features <- scale(abs(as.matrix(data[,2:74]) - as.matrix(data[,75:ncol(data)]))); #accuracy: 0.7684
#features <- abs(scale(as.matrix(data[,2:74]) - as.matrix(data[,75:ncol(data)]))); #accuracy: .79,  0.7758
#features <- scale(as.matrix(data[,2:74]) - as.matrix(data[,75:ncol(data)]))^2; #accuracy: .759, 0.7584
#-------------------------split up the data for testing and training------------------------------
#there is too much data for rapid iteration, use this to scale down how big the initial pool is during prototyping
useDataIndices <- createDataPartition(y=labels, p=.5, list=FALSE);
testDataIndices <- createDataPartition(y=labels[useDataIndices], p=.2, list=FALSE);
trainingLabels <- labels[useDataIndices]; trainingLabels <- trainingLabels[-testDataIndices];
testLabels <- labels[useDataIndices]; testLabels <- testLabels[testDataIndices];
trainingFeatures <- features[useDataIndices,]; trainingFeatures <- trainingFeatures[-testDataIndices,];
testFeatures <- features[useDataIndices,]; testFeatures <- testFeatures[testDataIndices,];
#run an SVM
svm <- svmlight(trainingFeatures,trainingLabels) #,pathsvm='/Users/Cybelle/Documents/grad_school/school/classes/2015-2016_spring/cs498daf/svm_light')
predictedLabels<-predict(svm, testFeatures)
foo<-predictedLabels$class #"foo" = class labels (1 or 0) for each item in test set
#get classification accuracy:
accuracy<-sum(foo==testLabels)/(sum(foo==testLabels)+sum(!(foo==testLabels)))
