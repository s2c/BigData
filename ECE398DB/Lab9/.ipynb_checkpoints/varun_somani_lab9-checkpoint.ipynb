{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 9 - Community Detection Algorithms II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Peter Kairouz and Pramod Viswanath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will learn how to design **efficient community detection** algorithms to cluster a given social network into non-overlapping communities. \n",
    "\n",
    "After filling this notebook and running all the cells, rename the file **lab9.ipynb** to **firstname_lastname_lab9.ipynb**, include your **well commented** code, and submit it by email. Avoid unneeded steps/computations and make sure your code runs before submitting it. Grading is based on your submission which is due at **4 p.m. March 30, 2016**. Your grade will be deducted 20 points for each day after the due date (late penalty).\n",
    "\n",
    "**This lab is partially adapted from UC Berkeley's EE126 by Prof. Kannan Ramchandran.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions needed from previous Lab 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "def G(n,p):\n",
    "    graph = [] \n",
    "    for i in xrange(n):\n",
    "        graph.append((i,i))\n",
    "    # in this lab, we describe a graph as a list of tuples enumerating all edges - node names can be numbers.\n",
    "    for i in xrange (0,n):\n",
    "        for e in xrange(i+1,n): #Go through all pairs of nodes\n",
    "            if (p > random() ): #if the probability of connection is greater than the generated probablity\n",
    "                graph.append((i,e)) #connect the nodes\n",
    "    return graph\n",
    "\n",
    "def find_highest(graph):\n",
    "    temp = []\n",
    "    for start, end in graph:\n",
    "        temp.append(start)\n",
    "        temp.append(end)\n",
    "    return max(temp)\n",
    "\n",
    "def adjacency_list(graph):\n",
    "    \"\"\"\n",
    "    Takes in the current representation of the graph, outputs an equivalent\n",
    "    adjacency list\n",
    "    Example: graph = [(0,1), (1,2), (2,0)] --> adjacency = [ [1, 2], [0, 2], [0, 1]]\n",
    "    \"\"\"\n",
    "    highest = find_highest(graph)                      #find the highest numbered node in the graph\n",
    "    adjacency = [[] for x in xrange(highest + 1 )]     #create an adjacency list of that length\n",
    "#    print len(adjacency)                               #Debug Code\n",
    "    for start,end in graph:\n",
    "        adjacency[start].append(end)                  #append to both nodes the other node\n",
    "        adjacency[end].append(start)\n",
    "    for x in xrange(0,highest + 1):\n",
    "        adjacency[x] = list(set(sorted(adjacency[x])))          #sort each list in adjacency so we have a nice clean lowest to highest\n",
    "        adjacency[x].remove(x)\n",
    "    return adjacency                               #and return\n",
    "\n",
    "\n",
    "def SBM(n,p,q):\n",
    "    \"\"\"\n",
    "    Let the first n/2 nodes be part of community A and \n",
    "    the second n/2 part of community B.\n",
    "    \"\"\"\n",
    "    assert(n % 2 == 0)\n",
    "    mid = int(n/2)\n",
    "    graph = []\n",
    "    for i in xrange(n):\n",
    "        graph.append((i,i))\n",
    "        \n",
    "    # create community A\n",
    "    # your code goes here\n",
    "    A = G(mid,p)                 \n",
    "    graph.extend(A) #add it to the graph\n",
    "    \n",
    "    # create community B  \n",
    "    # your code goes here\n",
    "    B = G(mid,p) #create a second community of the same size\n",
    "    i = 0        \n",
    "    for start,end in B:\n",
    "        B[i] = (start + mid,end + mid) #we need to increment all it's nodes by mid\n",
    "        i += 1\n",
    "    graph.extend(B) #and add it to the graph\n",
    "\n",
    "    # form connections between communities\n",
    "    for i in xrange(mid):\n",
    "        for j in xrange(mid, n):\n",
    "            if rnd.random() < q:\n",
    "                graph.append( (i, j) )\n",
    "    return graph\n",
    "\n",
    "#from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "def prob_recovery(L, n, alpha, beta):\n",
    "    mid = int(n/2)\n",
    "    ground_truth1 = tuple(np.arange(mid)) # community A\n",
    "    ground_truth2 = tuple(np.arange(mid, n)) # community B\n",
    "    p = (alpha)*np.log(n) / n\n",
    "    q = (beta)*np.log(n) / n\n",
    "    num_correct = 0\n",
    "    \n",
    "    # your code goes here\n",
    "    \n",
    "    # do the following L times\n",
    "    for i in xrange(0,L):\n",
    "    # generate an SBM graph\n",
    "        graph = SBM(n,p,q)\n",
    "    # use min_bisection(graph) to find the 2 communities in the randomly generated graph\n",
    "        A,B = min_bisection(graph)\n",
    "    # compare the communities returned by min_bisection to the true communities (community A and B)\n",
    "        if A==ground_truth1 and B==ground_truth2:\n",
    "            # if the match increment num_correct\n",
    "            num_correct +=1\n",
    "\n",
    "\n",
    "    \n",
    "    return float(num_correct/L)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Semidefinite Programming for Community Detection (50 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lab, we used the min-bisection algorithm to reconstruct the two communities. As we saw in one of the previous questions, min-bisection is extremely inefficient. In this section, we will develop a more efficient algorithm for the community detection problem. We will use $G(V, E)$ to denote the undirected graph that we observe, where $V$ is the set of nodes $(|V|=n)$, and $E$ is the set of edges.\n",
    "\n",
    "First, let's consider an intuitive algorithm to solve the community detection problem. As we have seen, the goal of community detection is to separate the nodes into two communities, such that the number of edges within the same community is as large as possible and the number of edges between two communities is as small as possible. To achieve this goal, we consider the \"score\" of a particular separation. For an edge within a community, we get one point; for an edge between two communities, we get minus one point. We want to maximize the score over all possible separations. We identify a choice of communities by a vector $x\\in\\mathbb{R}^n$ with $\\pm1$ entries such that $x_i$ will be $+1$ if node $i$ is in one community and $-1$ if it is in the other. We also define $A$ as the $n\\times n$ matrix with zero diagonal whose non diagonal entries are given by\n",
    "$$\n",
    "A_{ij}=\\begin{cases}\n",
    "1 & \\text{if }(i,j)\\in E\\\\\n",
    "-1 & \\text{if }(i,j)\\notin E\n",
    "\\end{cases}\n",
    "$$\n",
    "Then we can show that, maximizing the score is equivalent to the following optimization problem (think about the reason by yourself):\n",
    "\\begin{align}\n",
    "\\max &~~x^TAx \\\\\n",
    "s.t. &~~x_i=\\pm1.\n",
    "\\end{align}\n",
    "However, since this optimization problem is combinatorial and hard to solve, we need to relax the constraint that $x_i$ has to be $\\pm1$.\n",
    "\n",
    "Let's look at the objective of the optimization problem:\n",
    "$x^TAx$. According to knowledge in linear algebra, we know that $x^TAx=\\text{Tr}(x^TAx)=\\text{Tr}(Axx^T)$. Here, \"Tr\" denotes the trace of a square matrix, i.e., the sum of all the elements on the diagonal. We can see that $x^TAx=\\text{Tr}(x^TAx)$ is obvious because the trace of a scalar is still itself; and $\\text{Tr}(x^TAx)=\\text{Tr}(Axx^T)$ is because of the fact that $\\text{Tr}(AB)=\\text{Tr}(BA)$. If we denote the rank-one matrix $xx^T$ by $X$, then the previous optimization problem is equivalent to:\n",
    "\\begin{align}\n",
    "\\max &~~\\text{Tr}(AX) \\\\\n",
    "s.t. &~~X=xx^T\\text{ and }x_i=\\pm1.\n",
    "\\end{align}\n",
    "\n",
    "Since this problem is still hard to solve, we need to relax the constraints on $X$. As we can see, the diagonal elements of $X$ are all 1. Further, we can see that $X$ is positive semidefinite.\n",
    "(A matrix $D\\in\\mathbb{R}^{n\\times n}$ is called a positive semidefinite matrix if and only if for any vector $u\\in\\mathbb{R}^n$, there is $u^TDu\\ge 0$). \n",
    "An optimization problem with linear objective functions and matrix variables which are constrained to be positive semidefinite is called a semidefinite program (SDP). SDPs are convex optimization problems, and therefore, the global minimum can be found in polynomial time. Therefore, instead of solving the combinatorial optimization problem, we solve the following SDP problem:\n",
    "\\begin{align*}\n",
    "\\max &~~\\text{Tr}(AX)\\\\\n",
    "s.t. &~~X_{ii}=1\\\\\n",
    "&X\\succeq 0,\n",
    "\\end{align*}\n",
    "and hope the the relaxed optimization problem can give us the same answer as the original problem. It is proved that if $\\alpha$ and $\\beta$ satisfy some conditions, the solution to the SDP problem $X^*$ will be the outer product of the solution to the combinatorial optimization problem $x^*$, i.e., $X^*=x^*x^{*T}$. We will use the CVX package for Python to solve this SDP:\n",
    "\n",
    "http://cvxopt.org/.\n",
    "\n",
    "Install CVX in your computer and read the instructions on solving SDP using CVX:\n",
    "\n",
    "http://cvxopt.org/userguide/coneprog.html#semidefinite-programming.\n",
    "\n",
    "Specifically, we will solve the dual SDP problem. We will use different data structures from the previous parts in order to use CVX. Therefore, we define some new functions which are useful in this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions for Semi-Definite Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solvers.options['show_progress'] = False\n",
    "\n",
    "def generate_sbm(n, alpha, beta):\n",
    "    \"\"\"\n",
    "    Generate the A matrix for an SBM.\n",
    "    inputs:  n: total number of nodes, \n",
    "             alpha: parameter alpha corresponding to the in-cluster connection probability\n",
    "             beta: parameter beta corresponding to the cross-cluster connection probability\n",
    "    outputs: A: the \"A\" matrix for the SBM. A(i,i)=0 for all i; A(i,j) = 1 if (i,j) is an edge; A(i,j)=-1 otherwise.\n",
    "             truth: the ground truth of the two clusters, represented with +/- 1\n",
    "    both A and truth are in the CVX matrix data structure \n",
    "    \"\"\"\n",
    "    assert(n % 2 == 0)\n",
    "    mid = int(n/2)\n",
    "    # generate parameters\n",
    "    p = alpha*log(n)/n\n",
    "    q = beta*log(n)/n\n",
    "    # generate A matrix\n",
    "    A = zeros([n, n])\n",
    "    A[0:mid, mid:n] = np.random.binomial(1, q, (mid, mid))\n",
    "    for i in range(mid):\n",
    "        for j in range(i+1, mid):\n",
    "            A[i, j] = np.random.binomial(1, p)\n",
    "    for i in range(mid, n):\n",
    "        for j in range(i+1, n):\n",
    "            A[i, j] = np.random.binomial(1, p)\n",
    "    A = A+np.transpose(A)\n",
    "    A = (A-0.5)*2\n",
    "    for i in range(n):\n",
    "        A[i, i] = 0\n",
    "    # randomly permute the rows and columns\n",
    "    perm = np.random.permutation(n)\n",
    "    A = A[:, perm]\n",
    "    A = A[perm, :]\n",
    "    # find the ground truth\n",
    "    argperm = argsort(perm)\n",
    "    truth = zeros([n, 1])\n",
    "    truth[argperm[0:mid], 0] = 1\n",
    "    truth[argperm[mid:n], 0] = -1\n",
    "    # return A and truth\n",
    "    return matrix(A), matrix(truth)\n",
    "\n",
    "def is_correct(sol, truth):\n",
    "    \"\"\"\n",
    "    Checks whether the reconstruction found by SDP is correct.\n",
    "    inputs:  sol: the solution X^* found by SDP in CVX matrix data structure\n",
    "             truth: ground truth x^*, a column vector in CVX matrix data structure\n",
    "    outputs: 1 if reconstruction is correct; 0 otherwise\n",
    "    \"\"\"\n",
    "    # set a threshold for the difference between elements of X^* and x^*X^{*T}\n",
    "    th = 1e-4\n",
    "    difference = abs(sol-truth*transpose(truth))\n",
    "    if difference.max() < th:\n",
    "        # exact recovery\n",
    "        return 1\n",
    "    else:\n",
    "        # wrong recovery\n",
    "        return 0\n",
    "\n",
    "def recon_prob_sdp(n, alpha, beta):\n",
    "    \"\"\"\n",
    "    Find the probability of successful reconstruction given the parameters\n",
    "    inputs:  n: total number of nodes, \n",
    "             alpha: parameter alpha corresponding to the in-cluster connection probability\n",
    "             beta: parameter beta corresponding to the cross-cluster connection probability\n",
    "    outputs: the simulated probability of successful reconstruction\n",
    "    \"\"\"\n",
    "    assert(n % 2 == 0)\n",
    "    num_tests = 50\n",
    "    num_success = 0.0\n",
    "    for t in range(num_tests):\n",
    "        result = generate_sbm(n, alpha, beta)\n",
    "        A = result[0]\n",
    "        truth = result[1]\n",
    "\n",
    "        # Set parameters for the SDP\n",
    "        c = matrix(-1., (n, 1))\n",
    "        h = [-A]\n",
    "        G1 = zeros([n*n, n])\n",
    "        for i in range(n):\n",
    "            G1[i+n*i, i] = 1\n",
    "        G = [matrix(G1)]\n",
    "        sol = solvers.sdp(c, Gs=G, hs=h)\n",
    "        sol = sol['zs'][0]\n",
    "        if is_correct(sol, truth) == 1:\n",
    "            num_success = num_success + 1\n",
    "    return num_success/num_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Use the above helper functions to calculate the probability of exact recovery for $n=100$ and alpha, beta both varying between 0 and 5. Make a 3-d plot showing the probability of exact recovery as a function of alpha and beta.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-3f0a4eba0a1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mrecon_prob_sdp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-126-16656b098ec2>\u001b[0m in \u001b[0;36mrecon_prob_sdp\u001b[1;34m(n, alpha, beta)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;31m# Set parameters for the SDP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mG1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\rock-\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.pyc\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(subtype, data, dtype, copy)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;31m# now convert data to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m         \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "\n",
    "n = 100\n",
    "limit = 5 +1\n",
    "\n",
    "recon_prob_sdp(n, 1, 1)        \n",
    "\n",
    "alpha = np.arange(0,limit,1)\n",
    "beta = np.arange(0,limit,1)\n",
    "z=np.zeros((limit -1,limit -1))\n",
    "for a in alpha:\n",
    "    for b in beta:\n",
    "        z =  recon_prob_sdp(n, a, b)\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.plot_surface(alpha, beta, z, rstride=1, cstride=1, cmap='hot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Spectral Methods for Community Detection (40 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In spectral methods, a network is first represented by an  $n\\times n$ matrix $L$ (called Laplacian matrix) defined as \n",
    "$$\n",
    "L_{ij}=\\begin{cases}\n",
    "d_i & \\text{if } i = j \\\\\n",
    "-1 & \\text{if }(i,j)\\in E\\\\\n",
    "0 & \\text{if }(i,j)\\notin E,\n",
    "\\end{cases}\n",
    "$$\n",
    "where $d_i$ is the degree of the network. The smallest eigenvalue of $L$ is equal to zero because $L$ times the all 1s vector is equal to zero. The next $k$ smallest eigenvalues usually determine the number of clusters. In other words, if you can find $k$ eigenvalues that are very close to zero, then the graph has $k$ commnunities. If the graph has 2 communities, the eigenvector corresponding to the small non-zero eigenvalue can be used to figure out which nodes belong to community A and which ones belong to community B.\n",
    "\n",
    "### <font color=blue>Modify the following function to create the Laplacian matrix of a randomly generate SBM graph.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sbm(n, alpha, beta):\n",
    "    \"\"\"\n",
    "    Generate the A matrix for an SBM.\n",
    "    inputs:  n: total number of nodes, \n",
    "             alpha: parameter alpha corresponding to the in-cluster connection probability\n",
    "             beta: parameter beta corresponding to the cross-cluster connection probability\n",
    "    outputs: A: the \"A\" matrix for the SBM. A(i,i)=0 for all i; A(i,j) = 1 if (i,j) is an edge; A(i,j)=-1 otherwise.\n",
    "             truth: the ground truth of the two clusters, represented with +/- 1\n",
    "    both A and truth are in the CVX matrix data structure \n",
    "    \"\"\"\n",
    "    assert(n % 2 == 0)\n",
    "    mid = int(n/2)\n",
    "    # generate parameters\n",
    "    p = alpha*log(n)/n\n",
    "    q = beta*log(n)/n\n",
    "    # generate A matrix\n",
    "    A = zeros([n, n])\n",
    "    A[0:mid, mid:n] = random.binomial(1, q, (mid, mid))\n",
    "    for i in range(mid):\n",
    "        for j in range(i+1, mid):\n",
    "            A[i, j] = random.binomial(1, p)\n",
    "    for i in range(mid, n):\n",
    "        for j in range(i+1, n):\n",
    "            A[i, j] = random.binomial(1, p)\n",
    "    A = A+transpose(A)\n",
    "    A = (A-0.5)*2\n",
    "    for i in range(n):\n",
    "        A[i, i] = 0\n",
    "    # randomly permute the rows and columns\n",
    "    perm = random.permutation(n)\n",
    "    A = A[:, perm]\n",
    "    A = A[perm, :]\n",
    "    # find the ground truth\n",
    "    argperm = argsort(perm)\n",
    "    truth = zeros([n, 1])\n",
    "    truth[argperm[0:mid], 0] = 1\n",
    "    truth[argperm[mid:n], 0] = -1\n",
    "    # return A and truth\n",
    "    return matrix(A), matrix(truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Use the above modified helper function to calculate the probability of exact recovery for $n=100$ and alpha, beta both varying between 0 and 5. Make a 3-d plot showing the probability of exact recovery as a function of alpha and beta.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "\n",
    "n = 100\n",
    "limit = 5 +1\n",
    "\n",
    "recon_prob_sdp(n, 1, 1)        \n",
    "\n",
    "alpha = np.arange(0,limit,1)\n",
    "beta = np.arange(0,limit,1)\n",
    "z=np.zeros((limit -1,limit -1))\n",
    "for a in alpha:\n",
    "    for b in beta:\n",
    "        z =  recon_prob_sdp(n, a, b)\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.plot_surface(alpha, beta, z, rstride=1, cstride=1, cmap='hot')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
