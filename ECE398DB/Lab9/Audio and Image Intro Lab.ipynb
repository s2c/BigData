{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": "",
  "signature": "sha256:1ba023bdd06724f1cbd4c092cc474467053e5bbd447e3afde65c638a187a5afd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This lab is an introduction to audio and image processing. You will be learning how to use some Python packages that are commonly used in these domains. Part 1 deals will audio, and part 2 will be on images."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Part 1 - Loading and Visualizing Digital Audio"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from scipy.io import wavfile\n",
      "from matplotlib import pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sound is minute pressure changes in the medium it it travelling in, this pressure change is measured by a microphone and converted into signal levels. The most direct way to visualize this captured information is to plot out these values directly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "Fs, wav = wavfile.read('data/chopin.wav')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plotting the audio signal"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(16,5))\n",
      "\n",
      "plt.subplot(1, 2, 1)\n",
      "plt.plot(wav[:,0]);\n",
      "plt.title('Channel 0')\n",
      "\n",
      "plt.subplot(1, 2, 2)\n",
      "plt.plot(wav[:,1]);\n",
      "plt.title('Channel 1')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 1 - Baby steps\n",
      "\n",
      "1. Write a function to compute the length of the audio file in seconds\n",
      "2. Write a function to plot out short section of the audio clip instead of the whole length"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def audioLength(signal, samplingRate):\n",
      "    #signal is a single channel of the audio file, samplingRate is the, well, the sampling rate of the signal\n",
      "    #If you are lost here, check the documentation for scipy.io.wavefile :)\n",
      "    #your code here\n",
      "    \n",
      "    pass\n",
      "\n",
      "def getWindow(signal, (start, end), windowFunc=None):\n",
      "    #ignore windowFunc for now\n",
      "    #signal is a single channel of your audio file\n",
      "    #The function should return the signal values from [start,end), the value indexed by end is excluded\n",
      "    \n",
      "    #your code here\n",
      "    \n",
      "    pass\n",
      "    \n",
      "plt.plot(getWindow(wav[:,0], (0, 1000)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Better Visualization\n",
      "\n",
      "It is difficult to see what's happening in the audio signal from the plots above. To analyze audio content, in applications such as speaker recognition or audio content identification, a necessary tool is the **spectrogram**. The spectrogram can be used to visualize the frequency content of the audio signal as it progresses over time.\n",
      "\n",
      "Mathematically, the spetrogram is the **squared-magnitude** of \n",
      "the Fourier transform of overlapping segments, or windows, of the audio signal.\n",
      "To generate the spectrogram, the signal must first be separated into\n",
      "overlapping segments. If we denote the signal as \n",
      "$\\vec{x} = [x_{0}, x_{1},..., x_{N-1}]$, a one-dimensional vector of $N$ samples,\n",
      "Then the segments would be given as\n",
      "$$ \n",
      "\\vec{x}_{0}=[x_{0}, x_{1},..., x_{N}],\\\\\n",
      "\\vec{x}_{1}=[x_{M}, x_{M+1},..., x_{M+N}],\\\\\n",
      "\\vdots\\\\\n",
      "\\vec{x}_{i}=[x_{iM}, x_{iM + 1},..., x_{iM+N}],\n",
      "$$\n",
      "where $M$ is the step size between windows\n",
      "and $N$ is the length of each window. To generate a smoother spectrogram,\n",
      "it is common to multiply the windows element-wise with a \n",
      "*windowing filter* $\\vec{w}$. A popular choice of a window\n",
      "filter is the Hamming window."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Windowing Functions\n",
      "\n",
      "Using hard cut-offs at the boundaries of the windows can cause various undesirable artifacts. In order to reduce these effects, windowing functions can be applied to these rectangular clips. Numpy provides `hamming()` to generate what is known as the Hamming window. We apply this window to the signal we obtained above by performing an elementwise multiplication.\n",
      "\n",
      "Note:\n",
      "Not multiplying the signal by any fancy windowing function is sometimes called the rectangular window."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 1000\n",
      "w = np.hamming(N)      # generate a Hamming window of length N\n",
      "s = wav[0:N, 0] # how many samples does s have? N or N+1?\n",
      "\n",
      "plt.figure()\n",
      "plt.plot(w) # plot the window\n",
      "plt.title('Hamming Window')\n",
      "ax = plt.axes()\n",
      "ax.set_xlabel('time (samples)')\n",
      "ax.set_ylabel('amplitude')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 2\n",
      "\n",
      "Now modify the definition of your `getWindow()` function, it should now apply the hamming window to the signal that was obtained."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getWindow(signal, (start, end), windowFunc=None):\n",
      "    #signal is a single channel of your audio file\n",
      "    #The function should return the signal values from [start,end), the value indexed by end is excluded\n",
      "    #windowFunc should be a function that will generate a window function, here we will just pass in np.hamming\n",
      "    #your code here\n",
      "    \n",
      "    pass\n",
      "\n",
      "plt.plot(getWindow(wav[:,0], (0, 1000), np.hamming))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Fourier Transform\n",
      "\n",
      "Applying a Fourier Transform to a signal allows us to view it's frequency content.\n",
      "\n",
      "To generate the frequency content for the spectrogram, the **Fourier transform** is applied\n",
      "to the windowed segments of the input and the magnitude of the result is squared\n",
      "and stored,\n",
      "\n",
      "$$\\vec{f}_{i} = \\left\\|\\mathcal{FFT}\\left(\\vec{w}\\odot \\vec{x}_{i}\\right)\\right\\|^{2},$$\n",
      "\n",
      "where $\\odot$ represents elementwise multiplication. Note that the Fourier transform\n",
      "produces both negative and positive frequencies, but the content of the negative frequencies are\n",
      "redundant, since the spectrogram stores the *magnitude* of the FT result and we are dealing\n",
      "with *real* signals. Therefore, only $\\vec{f}_{i,[0:N/2 + 1]}$ is needed. The function **rfft()** takes\n",
      "care of this for you."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = np.fft.rfft(s)                   # Fourier transform of signal, keeping only the positive frequencies\n",
      "\n",
      "freq = np.arange(f.size)*(Fs/2.)/f.size    # generate frequencies for plot\n",
      "\n",
      "plt.plot(freq, np.absolute(f))\n",
      "plt.title('Magnitude of Fourier Transform of Signal')\n",
      "ax = plt.axes()\n",
      "ax.set_xlabel('frequency')\n",
      "ax.set_ylabel('magnitude')\n",
      "ax.set_xlim(0,22050);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 3\n",
      "\n",
      "1. What's the length of `f` in the code segment above? Why?\n",
      "1. Plot only the initial parts of the Fourier Transform, give a brief description/explanantion of what you see.\n",
      "1. Plot the frequency content of a rectangular window and a Hamming window.\n",
      "2. Give a brief description of the differences between these windows.\n",
      "1. Plot the FFT of a window of the signal using the rectangular window and one with a hamming window. Describe what you see briefly.\n",
      "\n",
      "For the plots, you might want to play with the scales on the axis to see better"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Frequency Domain Visualization\n",
      "\n",
      "Here we will utilize a built in function in matplotlib to plot the spectrogram of the audio signal. The spectrogram is computed from a overlapping sliding window of the audio signal, with the windowing function applied. This is typically called the Short Time Fourier Transform(STFT) of the audio signal. Each column in the plot represents a window of the signal, the y-axis represents the frequency and the color represents the magnitude."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, (ax1, ax2) = plt.subplots(ncols=2) # create plot\n",
      "fig.set_size_inches(16, 5)\n",
      "\n",
      "N=1024\n",
      "M=128\n",
      "\n",
      "# generate & plot spectrogram (built-in function)\n",
      "data, freqs, bins, im = ax1.specgram(wav[:,0], NFFT=N, noverlap=(N-M), window = np.hamming(N))   \n",
      "ax1.axis('tight')\n",
      "ax1.set_title('Spectrogram of Channel 0')\n",
      "ax1.set_ylabel('frequency (normalized)')\n",
      "ax1.set_xlabel('time (in samples)')\n",
      "\n",
      "data, freqs, bins, im = ax2.specgram(wav[:,1], NFFT=N, noverlap=(N-M), window = np.hamming(N))   \n",
      "ax2.axis('tight')\n",
      "ax2.set_title('Spectrogram of Channel 1')\n",
      "ax2.set_ylabel('frequency (normalized)')\n",
      "ax2.set_xlabel('time (in samples)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 4\n",
      "\n",
      "3. Looking at the spectrograms above, are you able to make some judgement on what's going on in the audio file without listening to it?\n",
      "4. Now listen to the provided wav file, are you able to gain make an educated guess at what the sound would be by looking at the spectrogram? Describe briefly."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Part 2 - Digital Images\n",
      "\n",
      "In this part, we will be looking at digital image representation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from PIL import Image"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read in the image file and convert it into a numpy array\n",
      "img = np.array(Image.open('data/roulettes.jpg'))\n",
      "\n",
      "plt.imshow(img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 5\n",
      "\n",
      "1. What is the shape of the array? What does each dimension represent?\n",
      "2. Generate plots of each channel seperately. Briefly describe what you see in each plot\n",
      "3. Propose a method of segmenting the planes from the sky. (You can just describe in words. Implementation is not required. (Extra credit))\n",
      "4. What is the size of the JPEG file provided? Recall that an image is suppose to be made of pixels and each pixels is about 3 bytes. Does this add up? Explain briefly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}