{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2", 
   "language": "python", 
   "name": "python2"
  }, 
  "language_info": {
   "codemirror_mode": {
    "name": "ipython", 
    "version": 2
   }, 
   "file_extension": ".py", 
   "mimetype": "text/x-python", 
   "name": "python", 
   "nbconvert_exporter": "python", 
   "pygments_lexer": "ipython2", 
   "version": "2.7.10"
  }, 
  "name": ""
 }, 
 "nbformat": 2, 
 "nbformat_minor": 0, 
 "orig_nbformat": 4, 
 "orig_nbformat_minor": 0, 
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "import matplotlib.pyplot as plt", 
      "from keras.datasets import mnist", 
      "from keras.models import Sequential", 
      "from keras.layers.core import Dense, Dropout, Activation, Flatten", 
      "from keras.layers.convolutional import Convolution2D, MaxPooling2D", 
      "from keras.utils import np_utils", 
      "", 
      "%matplotlib inline"
     ], 
     "language": "python", 
     "metadata": {}, 
     "outputs": [], 
     "prompt_number": null
    }, 
    {
     "cell_type": "markdown", 
     "metadata": {}, 
     "source": [
      "Keras is a Python package that sits on top of Theano or TensorFlow to help simplify some standard tasks in designing deep networks. You can find the documentation [here](http://keras.io/)", 
      "", 
      "For this lab, you would want to have Keras and Theano installed. "
     ]
    }, 
    {
     "cell_type": "markdown", 
     "metadata": {}, 
     "source": [
      "Keras provides some convenience functions to load popular public datasets. It will download and do all the standard stuff for you"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "# the data, shuffled and split between train and test sets", 
      "(X_train, y_train), (X_test, y_test) = mnist.load_data()", 
      "", 
      "img_rows = 28", 
      "img_cols = 28", 
      "nb_classes = 10", 
      "", 
      "", 
      "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)", 
      "X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)", 
      "X_train = X_train.astype('float32')", 
      "X_test = X_test.astype('float32')", 
      "X_train /= 255", 
      "X_test /= 255", 
      "print('X_train shape:', X_train.shape)", 
      "print(X_train.shape[0], 'train samples')", 
      "print(X_test.shape[0], 'test samples')", 
      "", 
      "# convert class vectors to binary class matrices", 
      "Y_train = np_utils.to_categorical(y_train, nb_classes)", 
      "Y_test = np_utils.to_categorical(y_test, nb_classes)"
     ], 
     "language": "python", 
     "metadata": {}, 
     "outputs": [], 
     "prompt_number": null
    }, 
    {
     "cell_type": "markdown", 
     "metadata": {}, 
     "source": [
      "The MNIST dataset is simple a set of 28x28 binary images of handwritten digits. Here we look at a few examples of how they look like."
     ]
    }, 
    {
     "cell_type": "markdown", 
     "metadata": {}, 
     "source": [
      "The $Y$ vector is the class label, if the object in the image is from the first class, the value in the first element of the Y vector is 1, with zeros for the rest. This is known as a 'One-Hot Encoding'.", 
      "", 
      "This vector is what we hope to reproduce with our classifier."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "#Change the idx to see different images and their labels.", 
      "#Make sure you understand this, if you are going to train a network on your own datasets,", 
      "#this is something you will have to do yourself", 
      "", 
      "idx = 160", 
      "print Y_train[idx]", 
      "plt.imshow(X_train[idx][0])"
     ], 
     "language": "python", 
     "metadata": {}, 
     "outputs": [], 
     "prompt_number": null
    }, 
    {
     "cell_type": "markdown", 
     "metadata": {}, 
     "source": [
      "# A Really Simple Model"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "metadata": {}, 
     "source": [
      "A simple way is just to use the raw values of every single pixel and find some way of combining them. Here, we are simply using common activation functions built into Keras. You are also able to use custom functions defined in Theano as activation functions."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "model0 = Sequential()", 
      "", 
      "#number of epochs to train for", 
      "nb_epoch = 12", 
      "#amount of data each iteration in an epoch sees", 
      "batch_size = 128", 
      "", 
      "model0.add(Flatten(input_shape=(1, img_rows, img_cols)))", 
      "model0.add(Dense(nb_classes))", 
      "model0.add(Activation('softmax'))", 
      "model0.compile(loss='categorical_crossentropy', ", 
      "             optimizer='sgd',", 
      "             metrics=['accuracy'])", 
      "", 
      "model0.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,", 
      "          verbose=1, validation_data=(X_test, Y_test))", 
      "", 
      "score = model0.evaluate(X_test, Y_test, verbose=0)", 
      "", 
      "print('Test score:', score[0])", 
      "print('Test accuracy:', score[1])"
     ], 
     "language": "python", 
     "metadata": {
      "scrolled": true
     }, 
     "outputs": [], 
     "prompt_number": null
    }, 
    {
     "cell_type": "markdown", 
     "metadata": {}, 
     "source": [
      "You should be able to get about 90% accuracy here. Seems pretty good for something so simple. This is merely a single layer!"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "metadata": {}, 
     "source": [
      "To see how your model looks like, you can use a built-in function to help you visualize"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "print(model0.summary())"
     ], 
     "language": "python", 
     "metadata": {}, 
     "outputs": [], 
     "prompt_number": null
    }, 
    {
     "cell_type": "markdown", 
     "metadata": {}, 
     "source": [
      "### Exercise:", 
      "", 
      "The network has a total parameter count of 7850, where does this number come from?"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "metadata": {}, 
     "source": [
      "# Adding convolution and some non linear layers"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "model_simple = Sequential()", 
      "", 
      "model_simple.add(Convolution2D(32, 3, 3, ", 
      "                               border_mode='valid', ", 
      "                               input_shape=(1, img_rows, img_cols)))", 
      "model_simple.add(Activation('relu'))", 
      "model_simple.add(MaxPooling2D(pool_size=(2,2)))", 
      "model_simple.add(Flatten())", 
      "model_simple.add(Dense(nb_classes))", 
      "model_simple.add(Activation('softmax'))", 
      "", 
      "model_simple.compile(loss='categorical_crossentropy',", 
      "              optimizer='sgd',", 
      "              metrics=['accuracy'])", 
      "", 
      "model_simple.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,", 
      "          verbose=1, validation_data=(X_test, Y_test))", 
      "score = model_simple.evaluate(X_test, Y_test, verbose=0)"
     ], 
     "language": "python", 
     "metadata": {}, 
     "outputs": [], 
     "prompt_number": null
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "print model_simple.summary()"
     ], 
     "language": "python", 
     "metadata": {}, 
     "outputs": [], 
     "prompt_number": null
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "print('Test score:', score[0])", 
      "print('Test accuracy:', score[1])"
     ], 
     "language": "python", 
     "metadata": {}, 
     "outputs": [], 
     "prompt_number": null
    }, 
    {
     "cell_type": "markdown", 
     "metadata": {}, 
     "source": [
      "## Exercise", 
      "", 
      "Now the model has 54410 parameters, where does this number come from?"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "metadata": {}, 
     "source": [
      "## Exercise", 
      "", 
      "Modify the above network to get the best accuracy possible. You will want to add more layers and try different activation functions. This may take a considerable amount of trial and error. On top on adding more layers, you should also tune parameters like learning rate for SGD, batch sizes, number of epochs etc.. (Google is your friend, >99% should be achievable)", 
      "", 
      "After you have gotten your results, you should write a few sentences on the effect of the the (tuning) parameters."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "model = Sequential()", 
      "", 
      "#Your code here"
     ], 
     "language": "python", 
     "metadata": {}, 
     "outputs": [], 
     "prompt_number": null
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "model.compile(loss='categorical_crossentropy',", 
      "              optimizer='sgd',", 
      "              metrics=['accuracy'])", 
      "", 
      "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,", 
      "          verbose=1, validation_data=(X_test, Y_test))", 
      "score = model.evaluate(X_test, Y_test, verbose=0)", 
      "", 
      "print('Test score:', score[0])", 
      "print('Test accuracy:', score[1])"
     ], 
     "language": "python", 
     "metadata": {}, 
     "outputs": [], 
     "prompt_number": null
    }, 
    {
     "cell_type": "markdown", 
     "metadata": {}, 
     "source": [
      "# Extra Credit", 
      "", 
      "Try designing some classifier networks for other publicly available datasets, for example the Caltech 101 from the previous lab. For the Caltech 101 dataset, you will need to do your own proper train/test/validation splitting and class label encoding, with deep networks, this is about the limit of what's possible on your laptop in a reasonable amount of time. Compare your accuracy with the methods published on Caltech 101's website, are you able to beat them?", 
      "", 
      "Other datasets possible are CIFAR-10 or CIFAR-100. If you have a large enough computer you may want to try ImageNet(this dataset is several hundred GB in size) if you are really ambitious. These datasets were created much more recently are are more difficult to deal with. ", 
      "", 
      "Have fun!"
     ]
    }
   ], 
   "metadata": {}
  }
 ]
}